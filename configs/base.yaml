defaults:
  - dataset: re10k_small

model:
  patch_size: 16
  max_input_images: 2
  channels: 3
  width: ${dataset.width}
  height: ${dataset.height}
  rand_input_image_embed: True
  perceptual_loss_weight: 0.5 # they use 0.5 for scene-level, 1.0 for object-level
  decoder_kwargs:
    dim: 768
    depth: 12
    heads: 16
    attn_dim_head: 64
    use_rmsnorm: True
    add_value_residual: True
    ff_glu: True
    ff_post_act_ln: True
    attn_qk_norm: True
    
  log: ${logger.log}
  use_wandb: ${logger.use_wandb}
  lr: ${train.lr}
  model_params: dp_${model.decoder_kwargs.depth}_dim_${model.decoder_kwargs.dim}_p_${model.patch_size}

train:
  seed: 42
  resume: False
  ckpt: ""
  lr: 4e-4
  trainer:
    limit_train_batches: 200
    check_val_every_n_epoch: 100
    max_epochs: 5000
    precision: 16-mixed
    accelerator: gpu

logger:
  log: False
  output_dir: ./outputs
  name: re10k_small_${model.model_params}_${dataset.data_params}_epo_${train.trainer.max_epochs}
  use_wandb: True
  wandb:
    project: lvsm
    name: ${logger.name}
