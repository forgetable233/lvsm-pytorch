data:
  width: 256
  height: 256
  batch_size: 1
  path: ""
  data_params: "w_${data.width}_h_${data.height}_bs_${data.batch_size}"

model:
  seed: 42
  resume: False
  ckpt: ""
  patch_size: 16
  max_input_images: 4
  channels: 3
  width: ${data.width}
  height: ${data.height}
  rand_input_image_embed: True
  perceptual_loss_weight: 0.5 # they use 0.5 for scene-level, 1.0 for object-level
  decoder_kwargs:
    dim: 256
    depth: 6
    heads: 8
    attn_dim_head: 64
    use_rmsnorm: True
    add_value_residual: True
    ff_glu: True
  model_params: "dp_${model.decoder_kwargs.depth}_dim_${model.decoder_kwargs.dim}_p_${model.patch_size}"
  log: ${logger.log}
  use_wandb: ${logger.use_wandb}

trainer:
  epoch: 2000
  val_check_interval: 100
  max_train_batch: 200

logger:
  log: False
  output_dir: "./outputs"
  name: "${model.model_params}_${data.data_params}_epo_${trainer.epoch}"
  use_wandb: False
  wandb:
    project: "lvsm"
    name: "${logger.name}"
